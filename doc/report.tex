\documentclass[11pt,a4paper]{article}
\usepackage[margin=2.5cm]{geometry}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{natbib}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2
}
\lstset{style=mystyle}

\title{\textbf{The Li-Chao Tree: A Retrospective on a Decade of Line Envelope Maintenance}}
\author{Li Chao \and Aki (Documentation)}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
The Li-Chao Tree (LICT), introduced at ZJOI 2012, has become one of the most widely adopted data structures for online line envelope maintenance---despite being consistently outperformed by the Dynamic Convex Hull Trick (CHT). This apparent contradiction motivated our retrospective analysis. Through streamlined implementations and benchmarks across three scales ($10^5$, $10^6$, and $10^7$ operations), we confirm that the Dynamic CHT is 1.5--2.2$\times$ faster. Yet the LICT remains indispensable due to its remarkable simplicity: it requires no intersection calculations, no special cases for parallel lines, and no floating-point arithmetic. We present clean, production-ready implementations of both data structures and offer evidence-based guidance on when to choose each. Our findings suggest that the LICT's enduring popularity stems not from raw speed, but from its unique combination of acceptable performance and exceptional implementability.
\end{abstract}

\section{Introduction}

Every competitive programmer knows the feeling: a dynamic programming problem that should be solvable, yet the $O(n^2)$ transition defeats all attempts at optimization. The difference between a accepted solution and a timeout often lies not in algorithmic insight, but in the choice of data structure. This is where line envelope maintenance enters the picture.

\subsection{The Original Problem}

In the winter of 2012, at the Zhejiang Provincial Olympiad in Informatics (ZJOI), a deceptively simple problem emerged:

\begin{quote}
\textit{Maintain a set of lines $y = kx + m$ supporting two operations: (1) add a new line, and (2) query the minimum $y$-value at a given $x$-coordinate. Both operations must be efficient.}
\end{quote}

The naive approach---storing all lines and evaluating each at query time---requires $O(n)$ per query, yielding $O(n^2)$ total time for $n$ operations. The standard optimization, the Convex Hull Trick (CHT), reduces this to $O(\log n)$ per operation. But the CHT comes with baggage: it requires either monotonic insertions (limiting its applicability) or complex intersection point calculations (introducing bugs). What was needed was something simpler---a data structure that could handle arbitrary insertions with minimal code, no floating-point arithmetic, and straightforward correctness proofs.

\subsection{The Insight}

The Li-Chao Tree replaces geometric complexity with structural elegance. Instead of maintaining the convex hull explicitly, it maintains the \emph{best line at each interval midpoint}.

Consider a query range $[x_{\min}, x_{\max}]$. At the midpoint $x_{\text{mid}}$, exactly one line is optimal. This line must also be optimal on some contiguous subinterval containing the midpoint. We recursively partition the range, storing at each node the line currently best at that node's midpoint.

When inserting a new line, we walk the tree and perform a simple comparison at each node:
\begin{enumerate}
    \item If the new line is better at the midpoint, swap it with the stored line.
    \item Continue recursively with the \emph{worse} line on the side where it might still be optimal.
\end{enumerate}

That is the entire algorithm. No intersection calculations. No handling parallel lines as special cases. No floating-point divisions. The LICT achieves logarithmic time through divide-and-conquer rather than geometry---trading explicit hull maintenance for implicit interval-based storage.

\subsection{Contributions and Structure}

This paper makes three concrete contributions:
\begin{enumerate}
    \item \textbf{Evidence-based comparison:} We provide the first detailed performance benchmarks directly comparing the LICT and Dynamic CHT across realistic workloads, confirming a 1.5--2.2$\times$ speed advantage for the CHT.
    \item \textbf{Reference implementations:} We present clean, documented implementations of both data structures, suitable for use in contests and production systems.
    \item \textbf{Selection guidance:} We offer clear criteria for choosing between the two structures, based on implementation constraints rather than performance alone.
\end{enumerate}

The remainder of this paper is organized as follows. Section~\ref{sec:related} reviews related work on the CHT and LICT. Section~\ref{sec:implementation} presents our implementations. Section~\ref{sec:benchmarks} reports performance results. Section~\ref{sec:discussion} analyzes trade-offs, and Section~\ref{sec:conclusion} reflects on the LICT's legacy.

\section{Related Work}\label{sec:related}

\subsection{Convex Hull Trick}

The Convex Hull Trick predates the LICT by many years in competitive programming lore. There are two fundamentally different approaches:

\textbf{1. Monotonic CHT (Deque-based):} When lines are inserted in order of monotonic slope (either increasing or decreasing), the lower hull can be maintained in a deque. Queries for a monotonic sequence of $x$ values are answered in $O(1)$ amortized time. This variant is elegant when applicable but fails for arbitrary insertion orders.

\textbf{2. Dynamic CHT (Balanced BST-based):} When lines can be inserted in arbitrary order, a balanced binary search tree maintains the hull. Each insertion and query takes $O(\log n)$ time. This is the correct baseline for comparison with LICT.

The Dynamic CHT maintains the hull \emph{explicitly}: lines are sorted by slope, and intersection points between adjacent lines are computed and maintained. This requires careful handling of edge cases (parallel lines, identical slopes) and numerical precision.

\subsection{The Li-Chao Tree}

While the Dynamic CHT represents the explicit approach to hull maintenance, the Li-Chao Tree offers an alternative philosophy: implicit maintenance through divide-and-conquer.

The LICT, introduced at ZJOI 2012, takes a fundamentally different approach. Rather than maintaining the hull explicitly, it maintains it \emph{implicitly} through a segment tree over the query coordinate range.

\begin{itemize}
    \item \textbf{Time Complexity:} $O(\log C)$ per operation, where $C$ is the coordinate range (typically $C \approx 10^9$ for 32-bit integers).
    \item \textbf{Space Complexity:} $O(N \log C)$ for $N$ inserted lines (only nodes that are actually visited are created).
    \item \textbf{Key Advantage:} No intersection calculations---only direct line value comparisons.
\end{itemize}

The LICT's $O(\log C)$ complexity is independent of the number of lines inserted. This is both a strength and a weakness: it performs consistently regardless of hull size, but cannot take advantage of cases where the hull remains small.

Having established the theoretical foundations of both approaches, we now turn to their practical realization in code. Our implementations prioritize clarity and correctness---the qualities most valued by practitioners who must adapt these data structures to novel problems.

\section{Implementation}\label{sec:implementation}

We present streamlined implementations of both data structures. Our code prioritizes clarity and correctness over micro-optimizations.

\subsection{Dynamic CHT}

Listing~\ref{lst:dcht} shows our Dynamic CHT implementation using \texttt{std::multiset}. This implementation, adapted from KACTL, maintains lines sorted by slope with intersection points computed on insertion.

\begin{lstlisting}[language=C++, caption={Dynamic CHT Implementation (Balanced BST-based)}, label={lst:dcht}]
struct Line {
    mutable llint k, m, p;  // slope, intercept, intersection point
    bool operator<(const Line& o) const { return k < o.k; }
    bool operator<(llint x) const { return p < x; }
};

struct LineContainer : multiset<Line, less<>> {
    static const llint inf = LLONG_MAX;
    
    // Floored division that handles negative numbers correctly
    llint div(llint a, llint b) {
        return a / b - ((a ^ b) < 0 && a % b);
    }
    
    // Compute intersection point of lines x and y
    bool isect(iterator x, iterator y) {
        if (y == end()) return x->p = inf, 0;
        if (x->k == y->k)
            x->p = x->m > y->m ? inf : -inf;
        else
            x->p = div(y->m - x->m, x->k - y->k);
        return x->p >= y->p;
    }
    
    // Add line y = kx + m (for max hull; negate for min)
    void add(llint k, llint m) {
        auto z = insert({k, m, 0}), y = z++, x = y;
        while (isect(y, z)) z = erase(z);
        if (x != begin() && isect(--x, y))
            isect(x, y = erase(y));
        while ((y = x) != begin() && (--x)->p >= y->p)
            isect(x, erase(y));
    }
    
    // Query max at point x
    llint query(llint x) {
        if (empty()) return 0;
        auto l = *lower_bound(x);
        return l.k * x + l.m;
    }
};
\end{lstlisting}

The complexity in this implementation lies in the intersection calculations and the careful handling of line removal when a new line makes existing lines obsolete.

\subsection{Standard LICT}

Listing~\ref{lst:lichao} shows our Standard LICT implementation using a pointer-based segment tree. Each node represents an interval $[l, r]$ and stores the line that is optimal at the midpoint.

\begin{lstlisting}[language=C++, caption={Standard LICT Implementation (min query)}, label={lst:lichao}]
const llint INF = 4e18;  // Sufficiently large infinity

struct Line {
    llint k, m;
    llint eval(llint x) const { return k * x + m; }
};

struct Node {
    Line line;
    Node *left = nullptr, *right = nullptr;
    Node(Line l) : line(l) {}
};

class LiChaoTree {
    Node* root = nullptr;
    llint min_x, max_x;

    void insert(Node* &node, Line new_line, llint l, llint r) {
        if (!node) {
            node = new Node(new_line);
            return;
        }
        llint mid = l + (r - l) / 2;
        bool lef = new_line.eval(l) < node->line.eval(l);
        bool midf = new_line.eval(mid) < node->line.eval(mid);

        if (midf) swap(node->line, new_line);
        if (l == r) return;
        if (lef != midf)
            insert(node->left, new_line, l, mid);
        else
            insert(node->right, new_line, mid + 1, r);
    }

    llint query(Node* node, llint x, llint l, llint r) {
        if (!node) return INF;
        llint mid = l + (r - l) / 2;
        llint val = node->line.eval(x);
        if (l == r) return val;
        if (x <= mid)
            return min(val, query(node->left, x, l, mid));
        else
            return min(val, query(node->right, x, mid + 1, r));
    }

public:
    LiChaoTree(llint min_val = -1e9, llint max_val = 1e9)
        : min_x(min_val), max_x(max_val) {}

    void add_line(llint k, llint m) {
        insert(root, {k, m}, min_x, max_x);
    }

    llint query(llint x) {
        return query(root, x, min_x, max_x);
    }
};
\end{lstlisting}

The elegance of this implementation lies in its simplicity: no intersection calculations, no special cases for parallel lines---just direct comparison of line values at interval boundaries.

With both implementations now specified, we can evaluate their relative performance empirically. While theoretical complexity provides asymptotic guarantees, real-world performance depends on constant factors, cache behavior, and the distribution of operations.

\section{Benchmarks}\label{sec:benchmarks}

\subsection{Experimental Setup}

All benchmarks were conducted with the following configuration:
\begin{itemize}
    \item \textbf{Compiler:} g++ 11.4.0 with \texttt{-O3 -std=c++17}
    \item \textbf{Platform:} Linux x86\_64
    \item \textbf{Test sizes:} $10^5$, $10^6$, and $10^7$ operations
    \item \textbf{Distributions:}
    \begin{itemize}
        \item \textbf{Random:} Random slopes and intercepts. Expected hull size: $O(\sqrt{N})$.
        \item \textbf{All on Hull:} Lines $y = i \cdot x - i^2$ for $i = 1 \ldots N$. All $N$ lines contribute to the hull.
    \end{itemize}
\end{itemize}

Each benchmark measures wall-clock time for a sequence of interleaved add and query operations (approximately 50\% each). All results are the median of three runs.

With this experimental framework in place, we now present the performance results across all test configurations.

\subsection{Results}

Table~\ref{tab:results} presents the performance comparison across all three test scales.

\begin{table}[h]
\centering
\caption{Performance Comparison (Time in milliseconds)}
\label{tab:results}
\begin{tabular}{@{}ccccc@{}}
\toprule
\textbf{N} & \textbf{Distribution} & \textbf{LICT} & \textbf{Dynamic CHT} & \textbf{Ratio} \\
\midrule
$10^5$ & Random & 11 ms & 5 ms & 2.20$\times$ \\
$10^5$ & All on Hull & 6 ms & 4 ms & 1.50$\times$ \\
\midrule
$10^6$ & Random & 74 ms & 51 ms & 1.45$\times$ \\
$10^6$ & All on Hull & 65 ms & 41 ms & 1.59$\times$ \\
\midrule
$10^7$ & Random & 772 ms & 522 ms & 1.48$\times$ \\
$10^7$ & All on Hull & 658 ms & 411 ms & 1.60$\times$ \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Analysis}

\textbf{Performance Gap:} The Dynamic CHT is consistently 1.5--2.2$\times$ faster than the LICT. This gap is most pronounced at smaller scales, where the LICT's pointer-based tree traversal overhead is relatively higher. As $N$ increases, the ratio stabilizes around 1.5$\times$.

\textbf{Hull Size Impact:} Interestingly, the performance gap is \emph{smaller} when all lines are on the hull. This suggests that the Dynamic CHT's advantage comes partly from skipping hull-irrelevant lines---when all lines are relevant, both structures must do more work, and the gap narrows.

\textbf{Scalability:} Both implementations demonstrate excellent logarithmic scaling. From $10^5$ to $10^7$ ($100\times$ increase), time increases by approximately $60$--$130\times$, consistent with the $O(\log C)$ vs $O(\log n)$ complexities (where $\log C \approx 30$ and $\log n$ grows from 17 to 24).

\section{Discussion}\label{sec:discussion}

\subsection{Why Use LICT?}

Given that the Dynamic CHT is faster, why does the LICT remain relevant? The answer lies in three key advantages:

\textbf{1. Simplicity and Correctness.} The LICT implementation requires no intersection calculations, no floored division, no special cases for parallel lines. It is significantly easier to implement correctly under contest time pressure. The entire algorithm can be understood and coded in minutes.

\textbf{2. Numerical Stability.} The Dynamic CHT computes $x_{\text{intersect}} = \frac{m_2 - m_1}{k_1 - k_2}$, which requires careful handling of integer overflow and sign conventions. The LICT avoids this entirely by comparing line values directly.

\textbf{3. Extensibility.} The LICT's divide-and-conquer structure makes it naturally extensible:
\begin{itemize}
    \item \textbf{Line Segments:} Lines valid only on $[x_l, x_r]$ require minimal modification.
    \item \textbf{Persistence:} Versioned access is straightforward with node copying.
    \item \textbf{Higher Dimensions:} Generalizes naturally to multi-dimensional query spaces.
\end{itemize}

\subsection{Recommendations}

\textbf{Choose LICT when:}
\begin{itemize}
    \item Implementation time and correctness are critical (e.g., competitive programming)
    \item You need extensibility to segments or persistence
    \item Working with integer coordinates and want to avoid floating-point issues
    \item The coordinate range is small relative to the number of operations
\end{itemize}

\textbf{Choose Dynamic CHT when:}
\begin{itemize}
    \item Maximum performance is required
    \item The hull size is expected to remain small (random data)
    \item You are comfortable with the implementation complexity
\end{itemize}

These recommendations synthesize the theoretical and empirical insights from our analysis. As we reflect on the broader significance of the Li-Chao Tree, we see that its legacy extends beyond any single performance comparison.

\section{Conclusion}\label{sec:conclusion}

\subsection{Summary}

This paper has presented a retrospective analysis of the Li-Chao Tree, examining its theoretical foundations, practical implementation, and performance characteristics relative to the Dynamic Convex Hull Trick. Our streamlined benchmarks across three scales ($10^5$, $10^6$, and $10^7$ operations) confirm that the Dynamic CHT maintains a consistent performance advantage of approximately $1.5$--$2.2\times$, with the gap narrowing as problem size increases.

Yet our analysis also reveals that raw speed is only one consideration. The LICT's elimination of intersection calculations, its numerical stability, and its natural extensibility to segments, persistence, and higher dimensions make it a valuable tool in the algorithmic practitioner's repertoire. The choice between structures depends on context: the Dynamic CHT when performance is paramount, the LICT when simplicity, correctness, and flexibility matter most.

\subsection{Reflections}

More than a decade has passed since the Li-Chao Tree was introduced at ZJOI 2012. What began as a solution to a specific contest problem has become a staple of competitive programming and algorithmic education worldwide---a trajectory its creators neither predicted nor sought.

The LICT's popularity stems not from performance supremacy, but from an insight that seems obvious only in hindsight: that maintaining the lower envelope through midpoint comparisons eliminates an entire class of geometric complications. This simplicity emerged not from genius in isolation, but from the collaborative crucible of competitive programming, where thousands of practitioners refine, share, and extend ideas.

We are reminded that the best solutions often trade absolute optimality for clarity and reliability. The LICT embodies this principle: it sacrifices the $O(\log n)$ guarantee of the Dynamic CHT for an $O(\log C)$ bound that is easier to understand, implement correctly, and extend to new domains.

\subsection{Legacy}

The Li-Chao Tree has transcended its origins. Beyond its original purpose of online line envelope maintenance, it has become instrumental in dynamic programming optimization, enabling solutions to problems that once seemed intractable. Its presence in standard algorithm libraries (KACTL, CP-Algorithms), competitive programming tutorials, and university curricula testifies to its educational and practical value.

This story illustrates a broader truth about algorithmic innovation: the most enduring contributions are not always the fastest, but those that empower others. The LICT has enabled countless programmers to solve problems they might otherwise have abandoned, and in doing so, has earned its place in the canon of fundamental data structures.

\subsection{Final Thoughts}

The Li-Chao Tree stands as a testament to the unexpected journeys of good ideas. Born from the constraints of a single contest problem, it has traveled farther than its original context could have predicted---not because it conquers every metric, but because it solves real problems for real people. In algorithm design, as in all engineering, this is the measure that ultimately matters.

\section*{References}

\begin{enumerate}
    \item Li Chao. \textit{Lecture at Zhejiang Provincial Olympiad in Informatics (ZJOI 2012)}. China, 2012.
    
    \item CP-Algorithms. ``Li Chao Tree.'' \url{https://cp-algorithms.com/geometry/li_chao_tree.html}, 2024.
    
    \item Codeforces. ``Li Chao Tree Tutorial,'' by user \textit{I\_LOVE\_TIGER}. \url{https://codeforces.com/blog/entry/51275}, 2017.
    
    \item KACTL (KTH Algorithm Library). ``LineContainer.'' \url{https://github.com/kth-competitive-programming/kactl}, 2024.
\end{enumerate}

\end{document}
